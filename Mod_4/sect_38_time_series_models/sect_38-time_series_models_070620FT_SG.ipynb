{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sect 38: Time Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10/16/20\n",
    "- online-ds-ft-070620"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "- Revisit types of time series trends and how to remove them.\n",
    "- Revisit seasonal decomposition`statsmodels.tsa.seasonal.seasonal_decompose`\n",
    "\n",
    "- Learn about PACF, ACF\n",
    "- Introduce ARIMA and SARIMA models.\n",
    "- Activity: SARIMA Models - Lab\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Questions\n",
    "- How do you decide how many lags to plot for ACF/PACF\n",
    "- Extra explanation of the ARMA readme.  \n",
    "- Explanation of how to read the autocorrelation and partial autocorrelation plots\n",
    "- Everything in the ARMA  models readme went right over my head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Pandas Timeseries Documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)\n",
    "- ['Timeseries Offset Aliases'](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases)\n",
    "- [Anchored Offsets](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#anchored-offsets)\n",
    "\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sect 38: TIME SERIES MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing the End of Sect 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:28:33.446826Z",
     "start_time": "2020-10-16T16:28:30.742214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsds v0.2.26 loaded.  Read the docs: https://fs-ds.readthedocs.io/en/latest/ \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_a1906392_0fcc_11eb_8480_acde48001122\" ><caption>Loaded Packages and Handles</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >Handle</th>        <th class=\"col_heading level0 col1\" >Package</th>        <th class=\"col_heading level0 col2\" >Description</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row0_col0\" class=\"data row0 col0\" >dp</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row0_col1\" class=\"data row0 col1\" >IPython.display</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row0_col2\" class=\"data row0 col2\" >Display modules with helpful display and clearing commands.</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row1_col0\" class=\"data row1 col0\" >fs</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row1_col1\" class=\"data row1 col1\" >fsds</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row1_col2\" class=\"data row1 col2\" >Custom data science bootcamp student package</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row2_col0\" class=\"data row2 col0\" >mpl</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row2_col1\" class=\"data row2 col1\" >matplotlib</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row2_col2\" class=\"data row2 col2\" >Matplotlib's base OOP module with formatting artists</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row3_col0\" class=\"data row3 col0\" >plt</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row3_col1\" class=\"data row3 col1\" >matplotlib.pyplot</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row3_col2\" class=\"data row3 col2\" >Matplotlib's matlab-like plotting module</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row4_col0\" class=\"data row4 col0\" >np</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row4_col1\" class=\"data row4 col1\" >numpy</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row4_col2\" class=\"data row4 col2\" >scientific computing with Python</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row5_col0\" class=\"data row5 col0\" >pd</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row5_col1\" class=\"data row5 col1\" >pandas</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row5_col2\" class=\"data row5 col2\" >High performance data structures and tools</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row6_col0\" class=\"data row6 col0\" >sns</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row6_col1\" class=\"data row6 col1\" >seaborn</td>\n",
       "                        <td id=\"T_a1906392_0fcc_11eb_8480_acde48001122row6_col2\" class=\"data row6 col2\" >High-level data visualization library based on matplotlib</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f937fbd1cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Pandas .iplot() method activated.\n"
     ]
    }
   ],
   "source": [
    "from fsds.imports import *\n",
    "pd.set_option('precision',3)\n",
    "plt.rcParams['figure.figsize'] = (12,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:28:37.710588Z",
     "start_time": "2020-10-16T16:28:37.675895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>burglary</th>\n",
       "      <th>common assault</th>\n",
       "      <th>larceny</th>\n",
       "      <th>robbery - street</th>\n",
       "      <th>auto theft</th>\n",
       "      <th>agg. assault</th>\n",
       "      <th>larceny from auto</th>\n",
       "      <th>shooting</th>\n",
       "      <th>robbery - residence</th>\n",
       "      <th>robbery - commercial</th>\n",
       "      <th>arson</th>\n",
       "      <th>homicide</th>\n",
       "      <th>robbery - carjacking</th>\n",
       "      <th>rape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-04</th>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-05</th>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            burglary  common assault  larceny  robbery - street  auto theft  \\\n",
       "2014-01-01        20              19       34                 8           9   \n",
       "2014-01-02        28              23       26                 4           7   \n",
       "2014-01-03        13              17       16                 2           3   \n",
       "2014-01-04        20              23       23                 7          14   \n",
       "2014-01-05        14              22       19                10          11   \n",
       "\n",
       "            agg. assault  larceny from auto  shooting  robbery - residence  \\\n",
       "2014-01-01            22                 15         2                    1   \n",
       "2014-01-02             6                 10         0                    1   \n",
       "2014-01-03            11                  6         1                    1   \n",
       "2014-01-04            14                 15         0                    1   \n",
       "2014-01-05             9                 13         2                    1   \n",
       "\n",
       "            robbery - commercial  arson  homicide  robbery - carjacking  rape  \n",
       "2014-01-01                     2    2.0       2.0                   1.0   4.0  \n",
       "2014-01-02                     1    2.0       3.0                   1.0   0.0  \n",
       "2014-01-03                     1    2.0       1.0                   0.0   0.0  \n",
       "2014-01-04                     1    2.0       0.0                   0.0   0.0  \n",
       "2014-01-05                     0    2.0       0.0                   2.0   1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2014-01-01', '2014-01-02', '2014-01-03', '2014-01-04',\n",
       "               '2014-01-05', '2014-01-06', '2014-01-07', '2014-01-08',\n",
       "               '2014-01-09', '2014-01-10',\n",
       "               ...\n",
       "               '2020-04-16', '2020-04-17', '2020-04-18', '2020-04-19',\n",
       "               '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23',\n",
       "               '2020-04-24', '2020-04-25'],\n",
       "              dtype='datetime64[ns]', length=2307, freq='D')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('baltimore_crime_2020_ts_070620ft.csv',\n",
    "                 index_col=0,parse_dates=[0])\n",
    "## Lazy fix to not changine col names to lowercase last class\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "df.index.freq = 'D'\n",
    "display(df.head())\n",
    "\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:28.294824Z",
     "start_time": "2020-10-16T16:18:27.690794Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = df.plot()\n",
    "ax.legend(bbox_to_anchor=([1,1]))\n",
    "ax.set(title=f'Baltimore Crime Rates - {df.index.freq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trends/Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;font-size:2em\">Trends</div>\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-removing-trends-online-ds-ft-100719/master/images/new_trendseasonal.png\" width=80%>\n",
    "\n",
    "<div style=\"text-align:center;font-size:2em\">Mean</div>\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-types-of-trends-online-ds-ft-100719/master/images/new_mean_nonstationary.png\" width=70%>\n",
    "<br><br>\n",
    "<div style=\"text-align:center;font-size:2em\">Variance</div>\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-types-of-trends-online-ds-ft-100719/master/images/new_cov_nonstationary.png\" width=70%>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:28.499116Z",
     "start_time": "2020-10-16T16:18:28.296764Z"
    }
   },
   "outputs": [],
   "source": [
    "## Pick a time series from above to work with\n",
    "ts = df['larceny']\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:28.633249Z",
     "start_time": "2020-10-16T16:18:28.501658Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def stationarity_check(TS,plot=True,col=None):\n",
    "    \"\"\"From: https://learn.co/tracks/data-science-career-v2/module-4-a-complete-data-science-project-using-multiple-regression/working-with-time-series-data/time-series-decomposition\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import adfuller\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "    if col is not None:\n",
    "        # Perform the Dickey Fuller Test\n",
    "        dftest = adfuller(TS[col]) # change the passengers column as required \n",
    "    else:\n",
    "        dftest=adfuller(TS)\n",
    " \n",
    "    if plot:\n",
    "        # Calculate rolling statistics\n",
    "        rolmean = TS.rolling(window = 8, center = False).mean()\n",
    "        rolstd = TS.rolling(window = 8, center = False).std()\n",
    "\n",
    "        #Plot rolling statistics:\n",
    "        fig = plt.figure(figsize=(12,6))\n",
    "        orig = plt.plot(TS, color='blue',label='Original')\n",
    "        mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "        std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Rolling Mean & Standard Deviation')\n",
    "#     plt.show(block=False)\n",
    "    \n",
    "    # Print Dickey-Fuller test results\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "\n",
    "    dfoutput = pd.Series(dftest[0:4],\n",
    "                         index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "        \n",
    "    dfoutput['stationary?'] = dfoutput['p-value']<.05\n",
    "\n",
    "    print (dfoutput)\n",
    "    \n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:28.716462Z",
     "start_time": "2020-10-16T16:18:28.635166Z"
    }
   },
   "outputs": [],
   "source": [
    "## Simpler Version of ADfullter func\n",
    "def adfuller_test_df(ts):\n",
    "    \"\"\"Returns the AD Fuller Test Results and p-values for the null hypothesis\n",
    "    that there the data is non-stationary (that there is a unit root in the data)\"\"\"\n",
    "    df_res = adfuller(ts)\n",
    "    names = ['Test Statistic','p-value','#Lags Used','# of Observations Used']\n",
    "    res  = dict(zip(names,df_res[:4]))\n",
    "    res['p<.05'] = res['p-value']<.05\n",
    "    res['Stationary?'] = res['p<.05']\n",
    "    \n",
    "    return pd.DataFrame(res,index=['AD Fuller Results'])\n",
    "adfuller_test_df(ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:29.056460Z",
     "start_time": "2020-10-16T16:18:28.718719Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stationarity_check(ts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Trends "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:29.347708Z",
     "start_time": "2020-10-16T16:18:29.059739Z"
    }
   },
   "outputs": [],
   "source": [
    "## Combine methods above into one DF\n",
    "ts.plot()\n",
    "adfuller_test_df(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trend Removal Methods\n",
    "- Differencing (`.diff()`)\n",
    "- Log-Transformation (`np.log`)\n",
    "- Subtract Rolling Mean (`ts-ts.rolling().mean()`)\n",
    "- Subtract Exponentially-Weighted Mean (`ts-ts.ewm().mean()`)\n",
    "- Seasonal Decomposition (`from statsmodels.tsa.seasonal import seasonal_decompose`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:29.663546Z",
     "start_time": "2020-10-16T16:18:29.350430Z"
    }
   },
   "outputs": [],
   "source": [
    "## Differencing \n",
    "ts0 = ts.diff().dropna()\n",
    "ts0.plot()\n",
    "adfuller_test_df(ts0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:29.975680Z",
     "start_time": "2020-10-16T16:18:29.665267Z"
    }
   },
   "outputs": [],
   "source": [
    "## Log Transform\n",
    "ts3 = np.log(ts)\n",
    "ts3.plot()\n",
    "adfuller_test_df(ts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:30.298275Z",
     "start_time": "2020-10-16T16:18:29.977466Z"
    }
   },
   "outputs": [],
   "source": [
    "## Subtract Rolling mean\n",
    "ts2 = (ts - ts.rolling(7).mean()).dropna()\n",
    "ts2.plot()\n",
    "adfuller_test_df(ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:30.596400Z",
     "start_time": "2020-10-16T16:18:30.300307Z"
    }
   },
   "outputs": [],
   "source": [
    "## Subtract Exponentially Weight Mean Rolling mean\n",
    "ts4 = (ts - ts.ewm(halflife=7).mean()).dropna()\n",
    "ts4.plot()\n",
    "adfuller_test_df(ts4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:31.101590Z",
     "start_time": "2020-10-16T16:18:30.598268Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomp = seasonal_decompose(ts) #, model='additive')#,model='mul')\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:31.763955Z",
     "start_time": "2020-10-16T16:18:31.102976Z"
    }
   },
   "outputs": [],
   "source": [
    "seasons = {'seasonal':decomp.seasonal,\n",
    "          'trend':decomp.trend,\n",
    "          'resid':decomp.resid}\n",
    "for data,ts_ in seasons.items():\n",
    "    ts_ = ts_.dropna()\n",
    "#     ts_.plot(title=data)\n",
    "    plt.show()\n",
    "    display(adfuller_test_df(ts_).style.set_caption(data))\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Time Series models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- White Noise Model\n",
    "- Randon Walk Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White Noise Model\n",
    "- 3 Properties:\n",
    "    - Fixed and constant mean\n",
    "    - Fixed and constant variance\n",
    "    - No correlation over time\n",
    "\n",
    "- Gaussian White Noise: A special case of a White Noise model is \n",
    "    - Mean is equal to zero\n",
    "    - variance is equal to 1\n",
    "    $$\\large Y_t = \\epsilon_t + \\theta * \\epsilon_{t-1}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:31.767670Z",
     "start_time": "2020-10-16T16:18:31.765212Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:32.181186Z",
     "start_time": "2020-10-16T16:18:31.770514Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "nyse = fs.datasets.load_ts_nyse_monthly(read_csv_kwds={'parse_dates':True,\n",
    "                                                     'index_col':'Month'})\n",
    "nyse.plot(title='Example White Noise Model')\n",
    "nyse.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Walk Model\n",
    "- Two Properties:\n",
    "    - Has no specified mean or variance\n",
    "    - Has a strong dependence over time\n",
    "\n",
    "- Mathematically, this can be written as:\n",
    "\n",
    "$$\\large Y_t = Y_{t-1} + \\epsilon_t$$\n",
    "\n",
    "- Where $\\epsilon_t$ is a *mean zero* white noise model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Walk with a Drift\":\n",
    "    - a drift parameter $c$, steering in a certain direction.\n",
    "$$\\large Y_t = c + Y_{t-1} + \\epsilon_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:33.005051Z",
     "start_time": "2020-10-16T16:18:32.182997Z"
    }
   },
   "outputs": [],
   "source": [
    "exch = fs.datasets.load_ts_exch_rates(read_csv_kwds={'parse_dates':['Frequency'],\n",
    "                                                     'index_col':'Frequency'})\n",
    "exch.plot(subplots=True,figsize=(12,6),title='Example Random Walk Model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When a random walk is differenced it returns a white noise. \n",
    "\n",
    "This is a result of the mathematical formula:\n",
    "\n",
    "$$Y_t = Y_{t-1} + \\epsilon_t$$\n",
    "which is equivalent to\n",
    "$$Y_t - Y_{t-1} = \\epsilon_t$$\n",
    "\n",
    "and we know that $\\epsilon_t$ is a mean-zero white noise process! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:33.556480Z",
     "start_time": "2020-10-16T16:18:33.006702Z"
    }
   },
   "outputs": [],
   "source": [
    "exch.diff().plot(subplots=True,figsize=(12,6),\n",
    "                 title='Differenced Random Walks Become White Noise');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation, Autocorrelation & Partial Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:33.941686Z",
     "start_time": "2020-10-16T16:18:33.557864Z"
    }
   },
   "outputs": [],
   "source": [
    "trends = fs.datasets.load_ts_google_trends(read_csv_kwds={'skiprows':1,\n",
    "                                                         'parse_dates':['Month'],\n",
    "                                                         'index_col':['Month']})\n",
    "trends.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:33.950848Z",
     "start_time": "2020-10-16T16:18:33.943342Z"
    }
   },
   "outputs": [],
   "source": [
    "## Correlation\n",
    "trends.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:34.182240Z",
     "start_time": "2020-10-16T16:18:33.952421Z"
    }
   },
   "outputs": [],
   "source": [
    "## Detrending Reveals Higher Underly Cross-Correlation\n",
    "trends.diff().plot()\n",
    "trends.diff().corr()\n",
    "## We Removed the Trend without Removing Seaonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:34.419688Z",
     "start_time": "2020-10-16T16:18:34.183834Z"
    }
   },
   "outputs": [],
   "source": [
    "## Seasonality causes correlations at specific times\n",
    "n=12\n",
    "ts = trends[['diet: (Worldwide)']]\n",
    "ts_shifted = ts.loc['2011':'2016']\n",
    "ts_shifted[f\"Shifted by {n}\"] = ts_shifted.shift(n)\n",
    "ts_shifted.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrating Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:34.598044Z",
     "start_time": "2020-10-16T16:18:34.425960Z"
    }
   },
   "outputs": [],
   "source": [
    "ts = trends['diet: (Worldwide)']\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:34.619677Z",
     "start_time": "2020-10-16T16:18:34.601518Z"
    }
   },
   "outputs": [],
   "source": [
    "## Generate 6 time-shifted columns\n",
    "total_shifts = 6\n",
    "shifts = [ts.shift(x).rename(f\"Diet shifted {x}\") for x in range(total_shifts)]\n",
    "res = pd.concat(shifts,axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:34.996221Z",
     "start_time": "2020-10-16T16:18:34.621325Z"
    }
   },
   "outputs": [],
   "source": [
    "res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:35.003441Z",
     "start_time": "2020-10-16T16:18:34.998098Z"
    }
   },
   "outputs": [],
   "source": [
    "res.corr()['Diet shifted 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:35.240211Z",
     "start_time": "2020-10-16T16:18:35.005088Z"
    }
   },
   "outputs": [],
   "source": [
    "total_shifts = 160\n",
    "shifts = [ts.shift(x).rename(f\"Diet shifted {x}\") for x in range(total_shifts)]\n",
    "res = pd.concat(shifts,axis=1)\n",
    "res.corr()[['Diet shifted 0']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACF & PACF  Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation Function Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - \"The **autocorrelation function** is a function that represents autocorrelation of a time series as a function of the time lag.\"\n",
    "- The autocorrelation function tells interesting stories about trends and seasonality. For example, if the original time series repeats itself every five days, you would expect to see a spike in the autocorrelation function at 5 days.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:35.428689Z",
     "start_time": "2020-10-16T16:18:35.241872Z"
    }
   },
   "outputs": [],
   "source": [
    "ts= trends['diet: (Worldwide)']\n",
    "\n",
    "pd.plotting.autocorrelation_plot(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:35.592092Z",
     "start_time": "2020-10-16T16:18:35.430495Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.graphics.tsaplots as tsa\n",
    "tsa.plot_acf(ts,lags=160);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial-Autocorrelation Function Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> \"The **partial autocorrelation function** can be interpreted as a regression of the series against its past lags.\n",
    " \n",
    " > It helps you come up with a possible order for the auto regressive term. The terms can be interpreted the same way as a standard linear regression, that is the contribution of a change in that particular lag while holding others constant. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:35.860388Z",
     "start_time": "2020-10-16T16:18:35.594142Z"
    }
   },
   "outputs": [],
   "source": [
    "tsa.plot_pacf(ts,lags=160);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.149656Z",
     "start_time": "2020-10-16T16:18:35.862188Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "# mpl.rcParams['figure.figsize'] = (12,4)\n",
    "plot_acf(ts);\n",
    "plot_pacf(ts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ARMA MODELS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive Model (AR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "An autoregressive (AR) model is when a value from a time series is regressed on previous values from the same time series.\n",
    "\n",
    "In words, the mathematical idea is the following:\n",
    "\n",
    "$$ \\text{Today = constant + slope} \\times \\text{yesterday + noise} $$\n",
    "\n",
    "Or, mathematically:\n",
    "$$\\large Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t$$\n",
    "\n",
    "Some notes based on this formula:\n",
    "- If the slope is 0, the time series is a white noise model with mean $\\mu$\n",
    "- If the slope is not 0, the time series is autocorrelated\n",
    "- Bigger slope means bigger autocorrelation\n",
    "- When there is a negative slope, the time series follows an oscillatory process\n",
    "\n",
    "<!---\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-arma-models-online-ds-pt-100719/master/images/AR_model.png\">\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-arma-models-online-ds-pt-100719/master/images/AR_PACF.png\"> --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The  Moving Average Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The Moving Average model can be described as the weighted sum of today's and yesterday's noise.\n",
    "\n",
    "In words, the mathematical idea is the following:\n",
    "\n",
    "$$ \\text{Today = Mean + Noise + Slope} \\times \\text{yesterday's noise} $$\n",
    "\n",
    "Or, mathematically:\n",
    "$$\\large Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}$$\n",
    "\n",
    "Some notes based on this formula:\n",
    "- If the slope is 0, the time series is a white noise model with mean $\\mu$\n",
    "- If the slope is not 0, the time series is autocorrelated and depends on the previous white noise process\n",
    "- Bigger slope means bigger autocorrelation\n",
    "- When there is a negative slope, the time series follow an oscillatory process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-order AR and MA models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's look at the formulas of AR and MA again:\n",
    "\n",
    "- AR: $Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t$\n",
    "- MA: $Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}$\n",
    "\n",
    "Note that these models are constructed in a way that processes only depend directly on the previous observation in the process. These models are so-called \"1st order models\", and denoted by AR(1) and MA(1) processes respectively. Let's look at AR(2) and MA(2).\n",
    "\n",
    "- AR(2): $$Y_t = \\mu + \\phi_1 * Y_{t-1}+\\phi_2 * Y_{t-2}+\\epsilon_t$$\n",
    "- MA(2): $$Y_t = \\mu +\\epsilon_t + \\theta_1 * \\epsilon_{t-1}+ \\theta_2 * \\epsilon_{t-2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA MODELS:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ARIMA Time Series Model\n",
    "\n",
    "One of the most common methods used in time series forecasting is known as the ARIMA model, which stands for **AutoregRessive Integrated Moving Average**. ARIMA is a model that can be fitted to time series data in order to better understand or predict future points in the series.\n",
    "\n",
    "Let's have a quick introduction to ARIMA. The ARIMA forecasting for a stationary time series is nothing but a linear (like a linear regression) equation. The predictors depend on the parameters (p,d,q) of the ARIMA model:\n",
    "\n",
    "### Number of AR (Auto-Regressive) terms (p): \n",
    "\n",
    "`p` is the auto-regressive part of the model. It allows us to incorporate the effect of past values into our model. Intuitively, this would be similar to stating that it is likely to rain tomorrow if it has been raining for past 3 days. AR terms are just lags of dependent variable. For instance if p is 5, the predictors for x(t) will be x(t-1)….x(t-5).\n",
    "\n",
    "### Number of Differences (d):\n",
    "\n",
    "`d` is the **Integrated** component of an ARIMA model. This value is concerned with the amount of differencing as it identifies the number of lag values to subtract from the current observation. Intuitively, this would be similar to stating that it is likely to rain tomorrow if the difference in amount of rain in the last *n* days is small. \n",
    "\n",
    "### Number of MA (Moving Average) terms (q): \n",
    "\n",
    "`q` is the moving average part of the model which is used to set the error of the model as a linear combination of the error values observed at previous time points in the past. MA terms form lagged forecast errors in prediction equation. For instance if q is 5, the predictors for x(t) will be e(t-1)….e(t-5) where `e(i)` is the difference between the moving average at ith instant and actual value.\n",
    "\n",
    "These three distinct integer values, (p, d, q), are used to parametrize ARIMA models. Because of that, ARIMA models are denoted with the notation `ARIMA(p, d, q)`. Together these three parameters account for seasonality, trend, and noise in datasets:\n",
    "\n",
    "* `(p, d, q)` are the non-seasonal parameters described above.\n",
    "* `(P, D, Q)` follow the same definition but are applied to the seasonal component of the time series. \n",
    "* The term `s` is the periodicity of the time series (4 for quarterly periods, 12 for yearly periods, etc.).\n",
    "\n",
    "A detailed article on these parameters is available [HERE](https://www.quantstart.com/articles/Autoregressive-Integrated-Moving-Average-ARIMA-p-d-q-Models-for-Time-Series-Analysis).\n",
    "\n",
    "The seasonal ARIMA method can appear daunting because of the multiple tuning parameters involved. In the next section, we will describe how to automate the process of identifying the optimal set of parameters for the seasonal ARIMA time series model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING PACF/ACF FOR AR/MA MODEL ORDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.459107Z",
     "start_time": "2020-10-16T16:18:36.151732Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_acf(ts);\n",
    "plot_pacf(ts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO FROM UDEMY\n",
    "\n",
    "- **USE ACF TO JUDGE IF MA OR AR COMPONENTS:**\n",
    "    - If lag 1 is positive: AR\n",
    "    - If lag 1 is negatige: MA\n",
    "    \n",
    "- **PACF is best for picking AR (p)**\n",
    "- **ACF is best for picking MA(q)**\n",
    "    - If sharp drop off at lag of k (k= point on x axis) means use an AR model of order k.\n",
    "    - If slow gradual decline: use MA\n",
    "    \n",
    "    \n",
    "___\n",
    "INFO FROM LESSONS:\n",
    "\n",
    "- AR(p):\n",
    "    - ACF for AR(p) would be strong until lag of p, then stagnant, then trail off. \n",
    "    - PACF for AR(p): Generally no correlation for lag values beyond p.\n",
    "- MA(q):\n",
    "    - ACF for MA(q) would show strong correlation up to a lag of q, the immedately delcine to minimal/no correction.\n",
    "    - PACF would show strong relationship to the lag and tailing off to no correlation afterwards.\n",
    "   \n",
    "- Notation is generally ARMA(p,q)\n",
    "- Example: ARMA(2,1) model equation\n",
    "     $$Y_t = \\mu + \\phi_1 Y_{t-1}+\\phi_2 Y_{t-2}+ \\theta \\epsilon_{t-1}+\\epsilon_t$$\n",
    "\n",
    "| Param| AR(p)   |   MA(q)  | ARMA(p,q)|\n",
    "|------|------|------|------|\n",
    "|   ACF | Tails off   |  Cuts off after lag q |  Tails off   |\n",
    "|   PACF | Cuts off after lag p  |   Tails off  |  Tails off  |\n",
    "  \n",
    "#### Note on modeling\n",
    "\n",
    "Seeing the table above, you might get an idea of why ACF and PACF are so useful when modeling! What you generally will try to do for any time series analysis is:\n",
    "\n",
    "- Detrend your time series using differencing. ARMA models represent stationary processes, so we have to make sure there are no trends in our time series\n",
    "- Look at ACF and PACF of the time series\n",
    "- Decide on the AR, MA, and order of these models\n",
    "- Fit the model to get the correct parameters and use for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Activity: SARIMA Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Repo folder > labs from class> sect_38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.917016Z",
     "start_time": "2020-10-16T16:18:36.460987Z"
    }
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pmdarima.auto_arima`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.918700Z",
     "start_time": "2020-10-16T16:18:25.713Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U pmdarima\n",
    "import pmdarima\n",
    "pmdarima.auto_arima?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining Questions from Sect 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset From Last Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.919882Z",
     "start_time": "2020-10-16T16:18:25.716Z"
    }
   },
   "outputs": [],
   "source": [
    "from fsds.imports import *\n",
    "pd.set_option('precision',3)\n",
    "plt.rcParams['figure.figsize'] = (12,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.921071Z",
     "start_time": "2020-10-16T16:18:25.719Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../baltimore_crime_2020_ts_070620ft.csv',\n",
    "                 index_col=0,parse_dates=[0])\n",
    "## Lazy fix to not changine col names to lowercase last class\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "df.index.freq = 'D'\n",
    "display(df.head())\n",
    "\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.922289Z",
     "start_time": "2020-10-16T16:18:25.722Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.923653Z",
     "start_time": "2020-10-16T16:18:25.725Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.924791Z",
     "start_time": "2020-10-16T16:18:25.728Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = df.plot()\n",
    "ax.legend(bbox_to_anchor=([1,1]))\n",
    "ax.set(title=f'Baltimore Crime Rates - {df.index.freq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.925868Z",
     "start_time": "2020-10-16T16:18:25.731Z"
    }
   },
   "outputs": [],
   "source": [
    "def ts_plot(df,title=f'Baltimore Crime Rates'):\n",
    "    ax = df.plot()\n",
    "    ax.get_legend().set_bbox_to_anchor([1,1])\n",
    "    ax.set(title=title)\n",
    "    fig = ax.get_figure()\n",
    "    # fig = plt.gcf()\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.927325Z",
     "start_time": "2020-10-16T16:18:25.734Z"
    }
   },
   "outputs": [],
   "source": [
    "# ts_plot(df,title='Baltimore Crime - By Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.928354Z",
     "start_time": "2020-10-16T16:18:25.737Z"
    }
   },
   "outputs": [],
   "source": [
    "# ts_plot(df.resample('W').sum(),title='Baltimore Crime - By Week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.929405Z",
     "start_time": "2020-10-16T16:18:25.740Z"
    }
   },
   "outputs": [],
   "source": [
    "# ts_plot(df.resample('M').sum(),title='Baltimore Crime - By Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends/Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;font-size:2em\">Trends</div>\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-removing-trends-online-ds-ft-100719/master/images/new_trendseasonal.png\" width=80%>\n",
    "\n",
    "<div style=\"text-align:center;font-size:2em\">Mean</div>\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-types-of-trends-online-ds-ft-100719/master/images/new_mean_nonstationary.png\" width=70%>\n",
    "<br><br>\n",
    "<div style=\"text-align:center;font-size:2em\">Variance</div>\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-types-of-trends-online-ds-ft-100719/master/images/new_cov_nonstationary.png\" width=70%>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.930379Z",
     "start_time": "2020-10-16T16:18:25.744Z"
    }
   },
   "outputs": [],
   "source": [
    "## Pick a time series from above to work with\n",
    "ts = df['larceny']\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.931344Z",
     "start_time": "2020-10-16T16:18:25.747Z"
    }
   },
   "outputs": [],
   "source": [
    "## plot\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.932530Z",
     "start_time": "2020-10-16T16:18:25.750Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def stationarity_check(TS,plot=True,col=None):\n",
    "    \"\"\"From: https://learn.co/tracks/data-science-career-v2/module-4-a-complete-data-science-project-using-multiple-regression/working-with-time-series-data/time-series-decomposition\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import adfuller\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "    if col is not None:\n",
    "        # Perform the Dickey Fuller Test\n",
    "        dftest = adfuller(TS[col]) # change the passengers column as required \n",
    "    else:\n",
    "        dftest=adfuller(TS)\n",
    " \n",
    "    if plot:\n",
    "        # Calculate rolling statistics\n",
    "        rolmean = TS.rolling(window = 8, center = False).mean()\n",
    "        rolstd = TS.rolling(window = 8, center = False).std()\n",
    "\n",
    "        #Plot rolling statistics:\n",
    "        fig = plt.figure(figsize=(12,6))\n",
    "        orig = plt.plot(TS, color='blue',label='Original')\n",
    "        mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "        std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Rolling Mean & Standard Deviation')\n",
    "#     plt.show(block=False)\n",
    "    \n",
    "    # Print Dickey-Fuller test results\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "\n",
    "    dfoutput = pd.Series(dftest[0:4],\n",
    "                         index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "        \n",
    "    dfoutput['sig'] = dfoutput['p-value']<.05\n",
    "    print (dfoutput)\n",
    "    \n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.933479Z",
     "start_time": "2020-10-16T16:18:25.753Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stationarity_check(ts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.934720Z",
     "start_time": "2020-10-16T16:18:25.756Z"
    }
   },
   "outputs": [],
   "source": [
    "## Simpler Version of ADfullter func\n",
    "def adfuller_test_df(ts):\n",
    "    \"\"\"Returns the AD Fuller Test Results and p-values for the null hypothesis\n",
    "    that there the data is non-stationary (that there is a unit root in the data)\"\"\"\n",
    "    df_res = adfuller(ts)\n",
    "    names = ['Test Statistic','p-value','#Lags Used','# of Observations Used']\n",
    "    res  = dict(zip(names,df_res[:4]))\n",
    "    res['Stationary Results'] = res['p-value']<.05\n",
    "    \n",
    "    return pd.DataFrame(res,index=['AD Fuller Results'])\n",
    "adfuller_test_df(ts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.935812Z",
     "start_time": "2020-10-16T16:18:25.759Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decomp = seasonal_decompose(ts) #, model='additive')#,model='mul')\n",
    "decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.936996Z",
     "start_time": "2020-10-16T16:18:25.762Z"
    }
   },
   "outputs": [],
   "source": [
    "trend = decomp.trend\n",
    "residuals = decomp.resid\n",
    "seasonal = decomp.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.937994Z",
     "start_time": "2020-10-16T16:18:25.765Z"
    }
   },
   "outputs": [],
   "source": [
    "ts.plot()\n",
    "residuals.plot(label='Residuals')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Trends "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Differencing (`.diff()`)\n",
    "- Log-Transformation (`np.log`)\n",
    "- Subtract Rolling Mean (`ts-ts.rolling().mean()`)\n",
    "- Subtract Exponentially-Weighted Mean (`ts-ts.ewm().mean()`)\n",
    "- Seasonal Decomposition (`from statsmodels.tsa.seasonal import seasonal_decompose`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.939128Z",
     "start_time": "2020-10-16T16:18:25.769Z"
    }
   },
   "outputs": [],
   "source": [
    "## Combine methods above into one DF\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.940213Z",
     "start_time": "2020-10-16T16:18:25.772Z"
    }
   },
   "outputs": [],
   "source": [
    "ts.rolling(7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.941330Z",
     "start_time": "2020-10-16T16:18:25.776Z"
    }
   },
   "outputs": [],
   "source": [
    "TS = ts.copy()\n",
    "DF = pd.DataFrame()\n",
    "DF['raw'] = TS\n",
    "\n",
    "DF['logged']  =np.log(TS)\n",
    "\n",
    "DF['diff-1'] = TS.diff(1)\n",
    "\n",
    "DF['Rolling-Mean-Subtracted window =7'] = TS - TS.rolling(7).mean()\n",
    "\n",
    "DF['EWM-Subtracted (halflife=7)'] = TS - TS.ewm(halflife=7).mean()\n",
    "\n",
    "DF.plot(subplots=True,figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.942420Z",
     "start_time": "2020-10-16T16:18:25.779Z"
    }
   },
   "outputs": [],
   "source": [
    "DF.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.943418Z",
     "start_time": "2020-10-16T16:18:25.782Z"
    }
   },
   "outputs": [],
   "source": [
    "DF.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.944582Z",
     "start_time": "2020-10-16T16:18:25.785Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get stationary results for each ts\n",
    "stationary_res = {}\n",
    "for col in DF.columns:\n",
    "    stationary_res[col] = adfuller_test_df(DF[col].bfill())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.945710Z",
     "start_time": "2020-10-16T16:18:25.788Z"
    }
   },
   "outputs": [],
   "source": [
    "## concatenate results \n",
    "res = pd.concat(stationary_res)\n",
    "res.index = [x[0] for x in res.index]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.946868Z",
     "start_time": "2020-10-16T16:18:25.791Z"
    }
   },
   "outputs": [],
   "source": [
    "df_window = pd.DataFrame()\n",
    "for window in [3,7,10,14,30]:\n",
    "    df_window[window] = ts - ts.rolling(window=window).mean()\n",
    "    \n",
    "df_window.plot(subplots=True)\n",
    "## Get stationary results for each ts\n",
    "stationary_res = {}\n",
    "for col in df_window.columns:\n",
    "    stationary_res[col] = adfuller_test_df(df_window[col].bfill())\n",
    "## concatenate results \n",
    "res = pd.concat(stationary_res)\n",
    "res.index = [x[0] for x in res.index]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.947815Z",
     "start_time": "2020-10-16T16:18:25.795Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def compare_detrending(ts,freq='D',agg='sum',diff=1,window=7, halflife=7,\n",
    "                      return_df=False):\n",
    "    \"\"\"Plots a timeseries (as the frequency provided) and several\n",
    "    other methods of detrending (Logged, Differenced, \n",
    "    Rolling Mean Subtracted,Exponential Mean Subtracted.)\"\"\"\n",
    "    \n",
    "    DF = pd.DataFrame()\n",
    "    \n",
    "    ## Resample timeseries and get aggregate data\n",
    "    TS = ts.resample(freq).agg(agg)\n",
    "    DF[f\"{ts.name}-raw\"] = TS.copy()\n",
    "    \n",
    "    ## Create figure and add sup title for overall figure\n",
    "    fig, axes = plt.subplots(nrows=5,figsize=(10,10))\n",
    "    plt.suptitle(f'{TS.name} by Freq={freq}'.title(),y=1.05,fontsize=(16))\n",
    "   \n",
    "    ## Plot raw timeseries\n",
    "    TS.plot(title='Raw',ax=axes[0])\n",
    "    \n",
    "    ## Plot Log-Tranformed Data\n",
    "    log_ts = np.log(TS)\n",
    "    log_ts.plot(title='Logged',ax=axes[1])\n",
    "    DF['logged'] = log_ts.copy()\n",
    "    \n",
    "    \n",
    "    ## Plot differenced data\n",
    "    diff_ts = TS.diff(diff)\n",
    "    diff_ts.plot(title=f'Diff {diff}',ax=axes[2])\n",
    "    DF['differenced'] = diff_ts.copy()\n",
    "    \n",
    "    \n",
    "    ## Plot rolling mean\n",
    "    TS2 = TS-TS.rolling(window).mean()\n",
    "    TS2.plot(title=f\"Rolling mean (window={window})\",ax=axes[3])\n",
    "    DF['rolling_mean_subtracted'] = TS2.copy()\n",
    "    \n",
    "    ## PLot Exponentoal Weighted Mean substraction\n",
    "    TS3 = TS-TS.ewm(halflife=halflife).mean()\n",
    "    TS3.plot(title=f\"EWM-Subtracted (halflife={halflife})\")    \n",
    "    DF['rolling_ewm_subtracted'] = TS3.copy()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if return_df:\n",
    "        plt.show()\n",
    "        return DF\n",
    "    else:\n",
    "        \n",
    "        return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.948927Z",
     "start_time": "2020-10-16T16:18:25.798Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_detrending(ts,window=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T16:18:36.949973Z",
     "start_time": "2020-10-16T16:18:25.801Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_detrending(ts,freq='W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.422px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
