{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByfUTZodQsND"
   },
   "source": [
    "# Sect 40: Neural Networks - Intro to Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10/20/20\n",
    "- online-ds-ft-070620"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Start By Discussing Biological Neural Networks (powerpoint)\n",
    "- Connect back to introduction from Learn\n",
    "- Demonstrate / play with Neural Network with Tensorflow Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions/ Comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biological Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> See `sect_40_bio_neural_networks.pptx` for introduction to how biological neurons work. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uceu7mnytDno"
   },
   "source": [
    "# Artificial Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "    \n",
    "- **The purpose of a neural network is to model $\\hat y \\approx y$ by minimizing loss/cost functions using gradient descent.**\n",
    "\n",
    "- Neural networks are very good with unstructured data. (images, audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-introduction-to-neural-networks-online-ds-ft-100719/master/images/new_first_network_num.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **Networks are comprised of sequential layers of neurons/nodes.**\n",
    "    - Each neuron applies a **linear transformation** and an **activation function** and outputs its results to all neurons in the next layer.\n",
    "    - Minimizing Loss functions by adjusting parameters (weights and bias) of each connection using gradient descent (forward and back propagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **Activation functions** control the output of a neuron.($\\hat y =f_{activation}(x)$ )\n",
    "    - Most basic activation function is sigmoid functin ($\\hat y =\\sigma(x)$)\n",
    "    - Choice of activation function controls the size/range of the output.\n",
    "- **Linear transformations** ( $z = w^T x + b$ ) are used control the output of the activation function .\n",
    "    - where $w^T $ is the weight(/coefficient), $x$ is the input, and  $b$ is a bias. \n",
    "        - weights: \n",
    "        - bias:\n",
    "        \n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-04-40-02-introduction-to-neural-networks-online-ds-ft-021119/master/figures/log_reg.png\">\n",
    "\n",
    "\n",
    "\n",
    "- **Loss functions** ($\\mathcal{L}(\\hat y, y) $)  measure inconsistency between predicted ($\\hat y$) and actual $y$\n",
    "    - will be optimized using gradient descent\n",
    "    - defined over 1 traning sample\n",
    "- **Cost functions** takes the average loss over all of the samples.\n",
    "    - $J(w,b) = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})$\n",
    "    - where $l$ is the number of samples\n",
    "\n",
    "\n",
    "- **Forward propagation** is the calculating  loss and cost functions.\n",
    "- **Back propagation** involves using gradient descent to update the values for  $w$ and $b$.\n",
    "    - $w := w- \\alpha\\displaystyle \\frac{dJ(w)}{dw}$ <br><br>\n",
    "    - $b := b- \\alpha\\displaystyle \\frac{dJ(b)}{db}$\n",
    "\n",
    "        - where $ \\displaystyle \\frac{dJ(w)}{dw}$ and $\\displaystyle \\frac{dJ(b)}{db}$ represent the *slope* of the function $J$ with respect to $w$ and $b$ respectively\n",
    "        - $\\alpha$ denote the *learning rate*. \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note On Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inputs:\n",
    "    - $n$: Number of inputs (columns) in the feature vector \n",
    "    - $l$: Number of items (rows) in the training set \n",
    "    - $m$: Number of items (rows) in the test set\n",
    "    \n",
    "- Input X:\n",
    "    - Will have shape $n$ x $l$ (number of features x number of training data points/rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Playground Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Tensorflow Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.60007&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/images/neural_network_steps.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "### Using the chain rule for updating parameters with sigmoid activation function example:\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-04-40-02-introduction-to-neural-networks-online-ds-ft-021119/master/figures/log_reg_deriv.png\" >\n",
    "- $\\displaystyle \\frac{dJ(w,b)}{dw_i} = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} \\frac{d\\mathcal{L}(\\hat y^{(i)}, y^{(i)})}{dw_i}$\n",
    " \n",
    " \n",
    "- For each training sample $1,...,l$ you'll need to compute:\n",
    "\n",
    "    - $ z^{(i)} = w^T x^ {(i)} +b $\n",
    "\n",
    "    - $\\hat y^{(i)} = \\sigma (z^{(i)})$\n",
    "\n",
    "    - $dz^{(i)} = \\hat y^{(i)}- y^{(i)}$\n",
    "\n",
    "- Then, you'll need to make update:\n",
    "\n",
    "    - $J_{+1} = - [y^{(i)} \\log (\\hat y^{(i)}) + (1-y^{(i)}) \\log(1-\\hat y^{(i)})$ (for the sigmoid function)\n",
    "\n",
    "    - $dw_{1, +1}^{(i)} = x_1^{(i)} * dz^{(i)}$\n",
    "\n",
    "    - $dw_{2, +1}^{(i)} = x_2^{(i)} * dz^{(i)}$\n",
    "\n",
    "    - $db_{+1}^{(i)} =  dz^{(i)}$\n",
    "\n",
    "    - $\\dfrac{J}{m}$, $\\dfrac{dw_1}{m}$, $\\dfrac{dw_1}{m}$, $\\dfrac{db}{m}$\n",
    "\n",
    "- After that, update: \n",
    "\n",
    "    $w_1 := w_1 - \\alpha dw_1$\n",
    "\n",
    "    $w_2 := w_2 - \\alpha dw_2$\n",
    "\n",
    "    $b := b - \\alpha db$\n",
    "\n",
    "    repeat until convergence!\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:34:38.901885Z",
     "start_time": "2020-10-20T15:34:38.343929Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from functions import *\n",
    "\n",
    "## Plot activation functions\n",
    "# act_funcs = [sigmoid,tanh,arctan,relu,leaky_relu]\n",
    "# [plot_activation(fn) for fn in act_funcs]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "## Activation Functions (will call $f_a$ here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **sigmoid:**<br>\n",
    "<!-- <img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-04-40-04-deeper-neural-networks-online-ds-ft-021119/master/index_files/index_33_1.png\" width=200> -->\n",
    "    - $ f_a=\\dfrac{1}{1+ \\exp(-z)}$\n",
    "    - outputs 0 to +1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:34:39.077258Z",
     "start_time": "2020-10-20T15:34:38.903846Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_activation(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **tanh (hyperbolic tan):**<br>\n",
    "    - $f_a = =\\dfrac{\\exp(z)- \\exp(-z)}{\\exp(z)+ \\exp(-z)}$\n",
    "    - outputs -1 to +1\n",
    "    - Generally works well in intermediate layers\n",
    "    - one of most popular functions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:34:39.275773Z",
     "start_time": "2020-10-20T15:34:39.079431Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_activation(tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **arctan**\n",
    "    -  similar qualities as tanh, but slope is more gentle than tanh\n",
    "    - outputs ~ 1.6 to 1.6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:34:39.463857Z",
     "start_time": "2020-10-20T15:34:39.278350Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_activation(arctan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "-  **Rectified Linear Unit (relu):**<br>\n",
    "    - most popular activation function\n",
    "    - Activation is exactly 0 when Z <0\n",
    "    - Makes taking directives slightly cumbersome\n",
    "    - $f_a=\\max(0,z)$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:34:39.642591Z",
     "start_time": "2020-10-20T15:34:39.465754Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_activation(relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlvqq-TbP5zO"
   },
   "source": [
    "- **leaky_relu:**\n",
    "    -  altered version of relu where the activatiom is slightly negative when $z<0$\n",
    "    - $f_a=\\max(0.001*z,z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:34:39.801510Z",
     "start_time": "2020-10-20T15:34:39.644456Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_activation(leaky_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Next class: Deep Neural Networks\n",
    "<img src=\"https://raw.githubusercontent.com/learn-co-students/dsc-introduction-to-neural-networks-onl01-dtsc-ft-070620/master/images/Deeper_network.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkJpdZlv3VNe"
   },
   "source": [
    "# Intro to Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYecj1xvmvEU"
   },
   "source": [
    "## Keras Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYecj1xvmvEU"
   },
   "source": [
    "- Tensors dimensions:\n",
    "    - Scalars = 0D tensors\n",
    "    - Vectors = 1D tensors\n",
    "    - Matrices = 2D tensors\n",
    "    - 3D tensors\n",
    "- A tensor is defined by 3 characteristics:\n",
    "    - rank or number of axes\n",
    "    - the shape\n",
    "    - the data type\n",
    "- Tensor basics - properties (from [here](https://pgaleone.eu/tensorflow/2018/07/28/understanding-tensorflow-tensors-shape-static-dynamic/#tensors-the-basic)):\n",
    "    - name\n",
    "    - type:\n",
    "        - tf.float32, tf.int64, tf.string\n",
    "    - rank:\n",
    "        - the number of dimension or the tensor. \n",
    "        - scalar = 0, vector = 1, etc.\n",
    "    - shape:\n",
    "\n",
    "### Important Data Manipulations in numpy\n",
    "\n",
    "- **Unrowing matrices:**\n",
    "    - e.g. turning a matrix of 790 images, which are 64 x 64 pixels and in RBG (3 colors) a (790, 64, 64, 3) matrix  into a matrix with 1 row for each image a ( 64*64*3, 790) matrix\n",
    "    - img_unrow = img.reshape(790, -1).T\n",
    "        - reshape -1 essentially means \"figure out how many, based upon the dat'\n",
    "- **Increasing the rank:**\n",
    "    - Vector with `np.shape()` returns  `(790,)`\n",
    "    - `np.reshape(vector, (1, 790))`\n",
    "- **Tensor indexling/slicing**\n",
    "    - just as python, `tensor[start_idx : end_idx]`\n",
    "    - left inclusive, right exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:34:39.804424Z",
     "start_time": "2020-10-20T15:34:39.802768Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U keras\n",
    "# !pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:34:42.597231Z",
     "start_time": "2020-10-20T15:34:39.807258Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "NbbVDhN0rDhV",
    "outputId": "4b5f722d-e72f-42bd-905b-b965aee215f8"
   },
   "outputs": [],
   "source": [
    "# Tensor indexing example using images\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "digit = train_images[10] #Select an arbitrary case for our example\n",
    "\n",
    "#Checking the shape of our tensor (in this case, the image)\n",
    "print('Raw Tensor shape:', train_images.shape)\n",
    "\n",
    "#Now performing some slices of our image:\n",
    "print('Tensor Slice [0:100] shape:', train_images[:100].shape)\n",
    "\n",
    "#Equivalently\n",
    "print('Tensor Slice [0:100] shape:', train_images[:100, :, :].shape)\n",
    "\n",
    "#Or verbosely:\n",
    "print('Tensor Slice [0:100] shape:', train_images[:100, :28, :28].shape)\n",
    "\n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary) #Display an example image for context\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bu64jh4K3oKt"
   },
   "source": [
    "## Basics of Building a Neural Network with Keras:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNk4Uz27wVZc"
   },
   "source": [
    "**Basics of Building a Neural Network with Keras:**\n",
    "1. Import required modules\n",
    "2. Decide on a network architecture (have only discussed sequential thus far)\n",
    "3. Adding layers - specifying layer type, number of neurons, activation functions, and, optionally, the input shape.\n",
    "4. Compile the model:\n",
    "    - Specify optimiziers\n",
    "    - specify loss functions\n",
    "    - specify metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:38:45.109463Z",
     "start_time": "2020-10-20T15:38:45.105707Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_images), len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:38:50.973121Z",
     "start_time": "2020-10-20T15:38:50.741324Z"
    }
   },
   "outputs": [],
   "source": [
    "## Reshape images as (num_images,-1)\n",
    "train_img_unrow = train_images.reshape(len(train_images), -1)\n",
    "test_img_unrow = test_images.reshape(len(test_images), -1)\n",
    "\n",
    "## Scale data\n",
    "train_img_unrow=train_img_unrow/255\n",
    "test_img_unrow =test_img_unrow/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:38:58.275860Z",
     "start_time": "2020-10-20T15:38:58.272295Z"
    }
   },
   "outputs": [],
   "source": [
    "## check train_img_unrow shape\n",
    "train_img_unrow.shape,test_img_unrow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:24:28.655249Z",
     "start_time": "2020-10-20T15:24:28.651740Z"
    }
   },
   "outputs": [],
   "source": [
    "## check out an individual array's shape from train_img_unrow\n",
    "train_img_unrow[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58e3B6PDzIjZ"
   },
   "source": [
    "5. Training the model\n",
    "    - `model.fit(X_train, y_train, epochs=20,batch_size=512,validation_data=(x_val,y_val))`\n",
    "    \n",
    "    - **batches:**\n",
    "        - a set of N samples, processed independently in parallel\n",
    "        - a batch determines how many samples are fed through before back-propagation. \n",
    "        - model only updates after a batch is complete.\n",
    "        - ideally have as large of a batch as your hardware can handle without going out of memory.\n",
    "            - larger batches usually run faster than smaller ones for evaluation/prediction. \n",
    "    - **epoch:**\n",
    "        - arbitrary cutoff / \"one pass over the entire dataset\", useful for logging and periodic evaluation\n",
    "        - when using kera's `model.fit` parameters `validation_data` or `validation_split`, these evaluations run at the end of every epoch.\n",
    "        - Within Keras can add callbacksto be run at the end of an epoch. Examples of these are learning rate changes and model checkpointing (saving).\n",
    "        \n",
    "    - **`history =  model.fit()` creates history object with .history attribute.**\n",
    "        - `history.history()` returns a dictionary of metrics from each epoch. \n",
    "            - `history.history['loss']` and `history.history['acc']`\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:36:37.837147Z",
     "start_time": "2020-10-20T15:36:29.826904Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ary82Ge-wfTb"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "## Make a Sequential Model with:\n",
    "## Hidden layer of 10 units with relu activation function\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(10, activation = 'relu'))\n",
    "\n",
    "## Add final layer with 1 neuron and activation='sigmoid'\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "## Compile with optimer as adam, loss as binary_crossentropy, and accuracy as metric\n",
    "model.compile(optimizer='adam',#optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',#'mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fitting the model (10 epochs, batch size=64, test data as validation data)\n",
    "history = model.fit(train_img_unrow, train_labels, epochs=10,\n",
    "                    batch_size=64, validation_data=(test_img_unrow, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:40:16.322678Z",
     "start_time": "2020-10-20T15:40:16.308895Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "## Make a dataframe out of history\n",
    "res_df = pd.DataFrame(history.history)#.plot()\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:32:44.048744Z",
     "start_time": "2020-10-20T15:32:43.423747Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot Losses\n",
    "ax1 = res_df[[col for col in res_df.columns if 'loss' in col]].plot(marker='.')\n",
    "ax1.set(xlabel='Epoch',ylabel='MSE')\n",
    "\n",
    "## Plot accuracy\n",
    "ax2 = res_df[[col for col in res_df.columns if 'acc' in col]].plot(marker='.')\n",
    "ax2.set(xlabel='Epoch',ylabel='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:42:04.924625Z",
     "start_time": "2020-10-20T15:42:04.785544Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get pred\n",
    "y_hat_test = model.predict(test_img_unrow)\n",
    "y_hat_test=y_hat_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T15:42:05.330692Z",
     "start_time": "2020-10-20T15:42:05.327655Z"
    }
   },
   "outputs": [],
   "source": [
    "len(y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2NJkNCFN9kQ"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "My Flatiron Bootcamp Notes - Mod 4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
